{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Opening the file\n",
    "sample_tl_raw = open(\"src/text data/Bible_Tagalog.txt\").read()\n",
    "\n",
    "# Printing the Ilokano Raw Data\n",
    "#sample_tl_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the raw data into sentences\n",
    "parsed_sp_tl_raw = sample_tl_raw.split(\"\\n\")\n",
    "\n",
    "#parsed_sp_tl_raw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sm_tl = pd.DataFrame(parsed_sp_tl_raw, columns = ['Sentence'])\n",
    "\n",
    "# Printing the first 5 rows of the DataFrame\n",
    "dict_sm_tl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the determiners file\n",
    "tl_determiners = open(\"src/text data/TL_Determiners.txt\").read()\n",
    "\n",
    "tl_determiners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the determiners file\n",
    "parsed_tl_dtmn = tl_determiners.split(\"\\n\")\n",
    "\n",
    "parsed_tl_dtmn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_punct(pText):\n",
    "    text_nopumct = \"\".join([char for char in pText if char not in string.punctuation])\n",
    "    return text_nopumct\n",
    "\n",
    "cleaned_sp_tl = [remove_punct(word) for word in parsed_sp_tl_raw]\n",
    "\n",
    "#cleaned_sp_tl[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = re.split('\\W+', text.lower())\n",
    "    return tokens\n",
    "\n",
    "\n",
    "tokenized_sp_tl = [tokenize(word) for word in parsed_sp_tl_raw]\n",
    "\n",
    "dict_sm_tl['Tokenized'] = tokenized_sp_tl\n",
    "dict_sm_tl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dtmn(sentence, dtmn_list):\n",
    "    \"\"\"\n",
    "    This function checks if the specific word in the sentence is a determiner, and extracts it.\n",
    "    \"\"\"\n",
    "    text = [word for word in sentence if word in dtmn_list]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "dict_sm_tl['Determiner'] = dict_sm_tl['Tokenized'].apply(lambda x: check_dtmn(x, parsed_tl_dtmn))\n",
    "\n",
    "dict_sm_tl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    Affixes\n",
    "\"\"\"\n",
    "PREFIX_SET = [\n",
    "    'nakikipag', 'pakikipag',\n",
    "    'pinakama', 'pagpapa',\n",
    "    'pinagka', 'panganga',\n",
    "    'makapag', 'nakapag',\n",
    "    'tagapag', 'makipag',\n",
    "    'nakipag', 'tigapag',\n",
    "    'pakiki', 'magpa',\n",
    "    'napaka', 'pinaka',\n",
    "    'ipinag', 'pagka',\n",
    "    'pinag', 'mapag',\n",
    "    'mapa', 'taga',\n",
    "    'ipag', 'tiga',\n",
    "    'pala', 'pina',\n",
    "    'pang', 'naka',\n",
    "    'nang', 'mang',\n",
    "    'sing', 'ma', # 'ma' is a prefix in Tagalog for Adjectives, Adverbs, and Verbs\n",
    "    'ipa', 'pam',\n",
    "    'pan', 'pag',\n",
    "    'tag', 'mai',\n",
    "    'mag', 'nam',\n",
    "    'nag', 'man',\n",
    "    'may', \n",
    "    'na', 'ni',\n",
    "    'pa', 'ka',\n",
    "    'um', 'in',\n",
    "    'i', 'nagpa', \n",
    "    'magka', 'nagka',\n",
    "    'ini'    \n",
    "]\n",
    "\n",
    "Adj_Prefix = [\n",
    "    'ma'\n",
    "]\n",
    "\n",
    "INFIX_SET = [\n",
    "    'um', 'in',\n",
    "]\n",
    "\n",
    "SUFFIX_SET = [\n",
    "    'syon','dor',\n",
    "    'ita', 'han',\n",
    "    'hin', 'ing',\n",
    "    'ang', 'ng',\n",
    "    'an', 'in',\n",
    "    'g',\n",
    "]\n",
    "\n",
    "PREPO_SET = [\n",
    "    \"sumasa\", 'gitna',\n",
    "    'ibabaw', 'ilalim',\n",
    "    'itaas', 'ibabaw',\n",
    "]\n",
    "\n",
    "PER_PRONOUN = [\n",
    "    'ako', 'ikaw', 'siya', 'kami', 'kayo', 'sila',\n",
    "    'akong', 'siyang', 'kaming', 'kayong', 'silang'\n",
    "    'ko', 'akin', 'sakin', 'amin', 'atin', 'inyo',\n",
    "    'kong', 'inyong',\n",
    "    'kata', 'mo', 'kanila', 'kanya', 'namin', 'natin',\n",
    "    'katang', 'mong', 'kanilang', 'kanyang'\n",
    "    'ninyo', 'niya', 'kayoy', 'ikay', 'akoy', 'siyay', 'kamiy',\n",
    "    'ninyong', 'niyang',\n",
    "    'silay', 'inyoy', 'kanilay', 'kanyay', 'niyay'\n",
    "]\n",
    "\n",
    "noun_dtmn_list = [\"ang\", \"ng\", \"mga\", \"si\", \"ay\", \"ni\"] # Noun Determiners\n",
    "\n",
    "adv_dtmn_list = [\"nang\"]\n",
    "\n",
    "prepo_dtmn_list = [\"sa\"]\n",
    "\n",
    "conj_list = ['at', 'o', 'saka', 'ngunit', 'datapwat']\n",
    "\n",
    "vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "\n",
    "adv_time_list = ['mamaya', 'ngayon', 'kahapon', 'bukas'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verb Affixer Checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_verb_affixes(word, prev2_word, prev_word, next_word, prefix_list, infix_list, suffix_list, isDone, hasVerbAffixes):\n",
    "    \"\"\"\n",
    "    This function checks if the specific word in the sentence has an affix, and extracts it.\n",
    "    \"\"\"\n",
    "    for prefix in prefix_list:\n",
    "        if word.startswith(prefix) and not isDone:\n",
    "            if word.startswith(\"mag\"):\n",
    "                if  word[3:5] == word[5:7] and not isDone:\n",
    "                    \"\"\"\n",
    "                    verbs starting with \"mag\" always repeat the next 4 letters of the word e.g. maglalakad, maglalaro, magbibihis\n",
    "                    \"\"\"\n",
    "                    hasVerbAffixes = True\n",
    "                    isDone = True\n",
    "\n",
    "                if word[3] in (vowels):\n",
    "                    \"\"\"\n",
    "                    verbs starting with \"mag\" and if the next letter is a vowel, the vowel is repeated e.g. magiikot, magaayos, maguusap\n",
    "                    \"\"\"\n",
    "                    if word[3] == word[4] and not isDone:\n",
    "                        hasVerbAffixes = True\n",
    "                        isDone = True\n",
    "            else:\n",
    "                hasVerbAffixes = True\n",
    "                isDone = True\n",
    "                \n",
    "    for infix in infix_list:\n",
    "        if word.__contains__(infix) and not isDone:\n",
    "            hasVerbAffixes = True\n",
    "            isDone = True\n",
    "            \n",
    "    for suffix in suffix_list:\n",
    "        \"\"\"\n",
    "        words ending with 'ang' are adverbs and after the adverbs are the nouns \n",
    "        \"\"\"\n",
    "        if word.endswith(suffix) and not isDone and not word.endswith(\"ang\") and not prev_word.endswith(\"ang\"):\n",
    "            hasVerbAffixes = True\n",
    "            isDone = True\n",
    "\n",
    "    if len(word) >= 4:\n",
    "        if word[:2] == word[2:4] and not isDone:\n",
    "            \"\"\"\n",
    "            if the first four characters of a word is repeated, then it is a verb\n",
    "            \"\"\"\n",
    "            hasVerbAffixes = True\n",
    "            isDone = True\n",
    "    \n",
    "    return hasVerbAffixes\n",
    "# end of check_verb_affixes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verb Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_verb(sentence, dtmn_list, prepo_list, pronoun_list):\n",
    "    \"\"\"\n",
    "    This function tags if the specific word in the sentence is a verb, and extracts it.\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    verb = [word for word in sentence if word in verb_list]\n",
    "    \"\"\"\n",
    "    verb = []\n",
    "    prev_word = \"\"\n",
    "    prev2_word = \"\"\n",
    "              \n",
    "    for word in sentence:\n",
    "        isDone = False\n",
    "        hasVerbAffixes = False\n",
    "                \n",
    "        try:\n",
    "            next_word = sentence[sentence.index(word) + 1]\n",
    "        except (ValueError, IndexError):\n",
    "            next_word = None\n",
    "            \n",
    "            \n",
    "        \"\"\"\n",
    "        checks if the word has an affix/es\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            hasVerbAffixes = check_verb_affixes(word, prev2_word, prev_word, next_word, PREFIX_SET, INFIX_SET, SUFFIX_SET, isDone, hasVerbAffixes)\n",
    "        except (ValueError, IndexError):\n",
    "            hasVerbAffixes = False\n",
    "        \n",
    "        \n",
    "        if word not in (dtmn_list + prepo_list + pronoun_list + conj_list):\n",
    "            if prev_word not in (noun_dtmn_list + adv_dtmn_list + prepo_dtmn_list): \n",
    "                if next_word in (noun_dtmn_list): \n",
    "                    \"\"\"\n",
    "                    if the previous word is not in the noun, adverb, and preposition determiner and \n",
    "                    the next word is a noun determiner\n",
    "                    \"\"\"\n",
    "                    if hasVerbAffixes:\n",
    "                        \"\"\"\n",
    "                        if the current word has a verb affix/es, then it is a verb\n",
    "                        \"\"\"\n",
    "                        verb.append(word)\n",
    "                        isDone = True\n",
    "                \n",
    "                if next_word in pronoun_list:\n",
    "                    verb.append(word)\n",
    "                    isDone = True\n",
    "\n",
    "            if prev_word == \"ay\" and not isDone:\n",
    "                if next_word in (\"ng\", \"sa\", \"nang\"):\n",
    "            # if prev_word in ('ay', 'ng', 'mga') and not word.endswith('ng') and hasAffixes and not isDone:\n",
    "                    \"\"\"\n",
    "                    if the previous word is 'ay' and the next word is 'ng' or 'sa', then it is a verb\n",
    "                    \"\"\"\n",
    "                    verb.append(word)\n",
    "                    isDone = True\n",
    "\n",
    "            if word and not isDone:\n",
    "                if word[:5] in (\"magpa\", \"nagka\") or word[:4] in (\"napa\", \"naka\") or word[:3] in (\"nag\"):\n",
    "                # if hasAffixes and not isDone:\n",
    "                    \"\"\"\n",
    "                    if the first five characters of a word start with \"magpa\" or \"nagka\", then it is a verb\n",
    "                    \"\"\"\n",
    "                    verb.append(word)\n",
    "                    isDone = True\n",
    "                if word[:3] in (\"mag\"):\n",
    "                    if next_word in (PER_PRONOUN, \"sa\", \"ni\", \"nang\"):\n",
    "                        verb.append(word)\n",
    "                        isDone = True\n",
    "        \n",
    "        if hasVerbAffixes and prev_word == None and not isDone:\n",
    "            if next_word in pronoun_list or (next_word in dtmn_list and next_word not in ('ng', 'mga')):\n",
    "                verb.append(word)\n",
    "                isDone = True\n",
    "               \n",
    "        prev_word = word\n",
    "        \n",
    "        try:\n",
    "            prev2_word = sentence[sentence.index(word) - 1]\n",
    "        except (ValueError, IndexError):\n",
    "            prev2_word = None\n",
    "        \n",
    "    return verb\n",
    "# end of function\n",
    "\n",
    "dict_sm_tl['Verb'] = dict_sm_tl['Tokenized'].apply(lambda x: tag_verb(x, parsed_tl_dtmn, PREPO_SET, PER_PRONOUN))\n",
    "dict_sm_tl.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noun Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_noun(sentence, per_noun_list):\n",
    "    \"\"\"\n",
    "    This function tags if the specific word in the sentence is a noun, and extracts it.\n",
    "    \"\"\"\n",
    "    noun = []\n",
    "    prev_word = \"\"\n",
    "    prev2_word = \"\"\n",
    "    adj_prefix = [\"ika\", \"pinaka\", \"pang\"]\n",
    "    adj_suffix = [\"ng\"]\n",
    "    \n",
    "    \n",
    "    for word in sentence:\n",
    "        \"\"\"\n",
    "        marks if the word is already tagged\n",
    "        \"\"\"\n",
    "        isDone = False\n",
    "        \n",
    "        \"\"\"\n",
    "        gets the next word in the sentence\n",
    "        \"\"\"\n",
    "        try:\n",
    "            next_word = sentence[sentence.index(word) + 1]\n",
    "        except (ValueError, IndexError):\n",
    "            next_word = None\n",
    "        \n",
    "        \n",
    "        if word in per_noun_list:\n",
    "            \"\"\"\n",
    "            if the word is a personal pronoun, then it is a noun\n",
    "            \"\"\"\n",
    "            noun.append(word)\n",
    "            isDone = True\n",
    "            \n",
    "        if len(sentence) == 1:\n",
    "            \"\"\"\n",
    "            if the sentence contains only one word, then it is a noun\n",
    "            \"\"\"\n",
    "            noun.append(word)\n",
    "            isDone = True\n",
    "    \n",
    "        if prev_word in (noun_dtmn_list) and word not in noun_dtmn_list and not isDone:\n",
    "            \"\"\"\n",
    "            if the previous word is a determiner and the word is not a determiner, then it is a noun\n",
    "            \"\"\"\n",
    "            isAdj = False\n",
    "            isVerb = False\n",
    "            \n",
    "            if prev_word == 'ay' and next_word == 'ng':\n",
    "                \"\"\"\n",
    "                if the previous word is 'ay' and the next word is 'ng', then it is a verb\n",
    "                \"\"\"\n",
    "                isVerb = True\n",
    "                \n",
    "            if word.endswith(\"ng\") and len(word.replace(\"ng\", \"\")) > 3:\n",
    "                \"\"\"\n",
    "                if the word ends with 'ng' and length of the word when 'ng' is removed is greater than 3, then it is an adjective\n",
    "                \"\"\"\n",
    "                isAdj = True\n",
    "            \n",
    "            if not isVerb and not isAdj:\n",
    "                for prefix in adj_prefix:\n",
    "                    \"\"\"\n",
    "                    if the word is an adjective it has an adjective prefix\n",
    "                    \"\"\"\n",
    "                    if not isDone:\n",
    "                        isAdj = word.startswith(prefix)\n",
    "                    if not isAdj and not isDone:\n",
    "                        if next_word != 'ng':\n",
    "                            noun.append(word)\n",
    "                            isDone = True\n",
    "                    if isAdj:  \n",
    "                        isDone = True\n",
    "                    \n",
    "        if prev_word.startswith('pang') and prev_word.endswith('ng') and not isDone:\n",
    "            \"\"\"\n",
    "            if the previous word is an adjective and if the next word is not an adjective\n",
    "            then the word is a noun\n",
    "            \"\"\"\n",
    "            noun.append(word)\n",
    "            isDone = True\n",
    "            \n",
    "            \n",
    "        if prev2_word == \"ay\" and prev_word.endswith(\"ang\") and word not in noun_dtmn_list and not isDone:\n",
    "            \"\"\"\n",
    "            if the previous previous word is \"ay\" and the previous word is \"ang\" \n",
    "            and the word is not a determiner then the word is a noun\n",
    "            \"\"\"\n",
    "            noun.append(word)\n",
    "            isDone = True\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        getting the previous word\n",
    "        \"\"\"\n",
    "        prev_word = word\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        getting the previous after the previous word\n",
    "        \"\"\"\n",
    "        try:\n",
    "            prev2_word = sentence[sentence.index(word) - 1]\n",
    "        except (ValueError, IndexError):\n",
    "            prev2_word = None\n",
    "        \n",
    "    return noun\n",
    "# end of function\n",
    "\n",
    "dict_sm_tl['Noun'] = dict_sm_tl['Tokenized'].apply(lambda x: tag_noun(x, PER_PRONOUN))\n",
    "dict_sm_tl.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjective Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_adj(sentence, dtmn_list, prepo_list, pronoun_list):\n",
    "    \"\"\"\n",
    "    This function tags if the specific word in the sentence is an adjective, and extracts it.\n",
    "    \"\"\"\n",
    "    adj = []\n",
    "    prev_word = \"\"\n",
    "    prev2_word = \"\"\n",
    "    \n",
    "    for word in sentence:\n",
    "        \"\"\"\n",
    "        marks if the word is already tagged\n",
    "        \"\"\"\n",
    "        isDone = False\n",
    "        hasVerbAffixes = False\n",
    "        \n",
    "        \"\"\"\n",
    "        gets the next word in the sentence\n",
    "        \"\"\"\n",
    "        try:\n",
    "            next_word = sentence[sentence.index(word) + 1]\n",
    "        except (ValueError, IndexError):\n",
    "            next_word = None\n",
    "        \n",
    "        \"\"\"\n",
    "        checks if the word is has an verb affix/es\n",
    "        \"\"\"\n",
    "        try:\n",
    "            hasVerbAffixes = check_verb_affixes(word, prev2_word, prev_word, next_word, PREFIX_SET, INFIX_SET, SUFFIX_SET, isDone, hasVerbAffixes)\n",
    "        except (ValueError, IndexError):\n",
    "            hasVerbAffixes = False\n",
    "            \n",
    "        if word not in (dtmn_list + prepo_list + pronoun_list + conj_list):\n",
    "            if word.startswith(\"ma\") and (next_word in noun_dtmn_list or next_word == 'na') and next_word not in ('ay', 'ng', 'mga') and  not hasVerbAffixes and not isDone:\n",
    "                \"\"\"\n",
    "                if the word is an adjective it has an adjective prefix 'ma' and the next word is noun determiner\n",
    "                eg. maayos na ang kalsada\n",
    "                \"\"\"\n",
    "                adj.append(word)\n",
    "                isDone = True\n",
    "                \n",
    "            if next_word == 'ang' and not hasVerbAffixes and prev_word not in noun_dtmn_list and not isDone:\n",
    "                \"\"\"\n",
    "                if the next word is 'ng' then the word is an adjective\n",
    "                \"\"\"\n",
    "                adj.append(word)\n",
    "                isDone = True\n",
    "            \n",
    "            if word.endswith(\"ng\") and not hasVerbAffixes and not isDone:\n",
    "                \"\"\"\n",
    "                if the word ends with 'ng', then it is an adjective\n",
    "                eg. dalawang bahay\n",
    "                \"\"\"\n",
    "                adj.append(word)\n",
    "                isDone = True\n",
    "            \n",
    "            if prev_word in ('ay', 'na') and not prev2_word.startswith('ika') and (not hasVerbAffixes or word.startswith('ma')) and not isDone: # tinanggal ko muna yung \"and not hasVerbAffixes\"\n",
    "                \"\"\"\n",
    "                if the previous word is 'ay' or 'na', then it is an adjective\n",
    "                eg. salamin na parihaba\n",
    "                \"\"\"\n",
    "                adj.append(word)\n",
    "                isDone = True\n",
    "            \n",
    "            \n",
    "        \"\"\"\n",
    "        getting the previous word\n",
    "        \"\"\"\n",
    "        prev_word = word\n",
    "        \n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        getting the previous after the previous word\n",
    "        \"\"\"\n",
    "        try:\n",
    "            prev2_word = sentence[sentence.index(word) - 1]\n",
    "        except (ValueError, IndexError):\n",
    "            prev2_word = None\n",
    "            \n",
    "    return adj\n",
    "# end of function\n",
    "\n",
    "dict_sm_tl['Adjective'] = dict_sm_tl['Tokenized'].apply(lambda x: tag_adj(x, parsed_tl_dtmn, PREPO_SET, PER_PRONOUN))\n",
    "dict_sm_tl.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adverb Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_adv(sentence):\n",
    "    \"\"\"\n",
    "    This function tags if the specific word in the sentence is an adverb, and extracts it.\n",
    "    \"\"\"\n",
    "    adverb = []\n",
    "    prev_word = \"\"\n",
    "    prev2_word = \"\"\n",
    "    next_word = \"\"\n",
    "    \n",
    "    for word in sentence:\n",
    "        \"\"\"\n",
    "        marks if the word is already tagged\n",
    "        \"\"\"\n",
    "        isDone = False\n",
    "        hasVerbAffixes = False\n",
    "        \n",
    "        \"\"\"\n",
    "        gets the next word in the sentence\n",
    "        \"\"\"\n",
    "        try:\n",
    "            next_word = sentence[sentence.index(word) + 1]\n",
    "        except (ValueError, IndexError):\n",
    "            next_word = None\n",
    "            \n",
    "        \"\"\"\n",
    "        checks if the word is has an verb affix/es\n",
    "        \"\"\"\n",
    "        try:\n",
    "            hasVerbAffixes = check_verb_affixes(word, prev2_word, prev_word, next_word, PREFIX_SET, INFIX_SET, SUFFIX_SET, isDone, hasVerbAffixes)\n",
    "        except (ValueError, IndexError):\n",
    "            hasVerbAffixes = False\n",
    "            \n",
    "        if word not in PER_PRONOUN:\n",
    "            if word.startswith('ma') and not word.startswith('mag') and (next_word in PER_PRONOUN or next_word == 'na') and next_word not in ('ay', 'ng', 'mga') and not isDone:\n",
    "                \"\"\"\n",
    "                if the word is an adverb it has an adverb prefix 'ma' and the next word is a pronoun\n",
    "                eg. mabilis na magsulat\n",
    "                \"\"\"\n",
    "                adverb.append(word)\n",
    "                isDone = True\n",
    "            \n",
    "            if prev_word == 'nang' and (not hasVerbAffixes or word.startswith('ma')) and next_word not in ('ay', 'ng', 'mga') and not isDone:\n",
    "                \"\"\"\n",
    "                if the previous word is 'nang' and starts with 'ma' or not have verb affixes and next word is not \"ay, ng, or mga\", then it is an adverb\n",
    "                eg. tumalon nang mataas\n",
    "                \"\"\"\n",
    "                adverb.append(word)\n",
    "                isDone = True\n",
    "                \n",
    "            if word in adv_time_list and not isDone:\n",
    "                \"\"\"\n",
    "                if the word is an adverb of time, then it is an adverb\n",
    "                eg. aalis bukas\n",
    "                \"\"\"\n",
    "                adverb.append(word)\n",
    "                isDone = True\n",
    "                \n",
    "            if next_word == 'na' and not hasVerbAffixes and not isDone:\n",
    "                \"\"\"\n",
    "                if the next word is 'na' then the word is an adverb\n",
    "                eg. tunay na maganda\n",
    "                \"\"\"\n",
    "                adverb.append(word)\n",
    "                isDone = True\n",
    "            \n",
    "            if prev_word.startswith('ma') and not prev_word.startswith('mag') and (hasVerbAffixes or word.startswith('mag')) and not isDone:\n",
    "                \"\"\"\n",
    "                if the previous word is an adverb the word is a verb\n",
    "                eg. mabagal magpalit\n",
    "                \"\"\"\n",
    "                adverb.append(prev_word)\n",
    "                isDone = True\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        getting the previous word\n",
    "        \"\"\"\n",
    "        prev_word = word\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        getting the previous after the previous word\n",
    "        \"\"\"\n",
    "        try:\n",
    "            prev2_word = sentence[sentence.index(word) - 1]\n",
    "        except (ValueError, IndexError):\n",
    "            prev2_word = None\n",
    "                \n",
    "    return adverb\n",
    "# end of function\n",
    "\n",
    "dict_sm_tl['Adverb'] = dict_sm_tl['Tokenized'].apply(lambda x: tag_adv(x))\n",
    "dict_sm_tl.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_sen = dict_sm_tl['Tokenized'].array[7]\n",
    "# temp_sen = tokenize(\"iniligay ng guro ang libro sa mesa\")\n",
    "temp_sen = tokenize(\"mahina magsalita\")\n",
    "print(temp_sen)\n",
    "\n",
    "# tagged_sen = tag_verb(temp_sen, parsed_tl_dtmn, PREPO_SET, PER_PRONOUN) # verb tagger\n",
    "# tagged_sen = tag_noun(temp_sen, PER_PRONOUN) # noun tagger\n",
    "# tagged_sen = tag_adj(temp_sen, parsed_tl_dtmn, PREPO_SET, PER_PRONOUN) # adjective tagger\n",
    "tagged_sen = tag_adv(temp_sen) # adverb tagger\n",
    "print(tagged_sen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd5e40cb983109c15fc1053f6f3e661cc97e68e07c1758cdbd2441c60186ce19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
