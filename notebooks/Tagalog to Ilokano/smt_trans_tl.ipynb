{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Machine Translation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rule_based_tl import dict_tl, remove_punct, tokenize, tag\n",
    "from doc_trans_tl import combine_tokens\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of the Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tl_il_lm = pd.read_json('src/json data/Tagalog to Ilokano/Example-Based/Language Model/dict_tl_il_lang_mod.json')\n",
    "\n",
    "dict_tl_il_lm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting the Structure Columns in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_struct = dict_tl_il_lm['Tagalog Structure'].tolist()\n",
    "il_struct = dict_tl_il_lm['Ilokano Structure'].tolist()\n",
    "il_struct_count = dict_tl_il_lm['Ilokano Structure Count'].tolist()\n",
    "\n",
    "# print(il_struct_count[0].index(max(il_struct_count[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting the SMT columns in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    TF-IDF\n",
    "\"\"\"\n",
    "vb_tl_tf_idf_list = dict_tl.dict_vb['Tagalog Verb TF-IDF'].tolist()\n",
    "nn_tl_tf_idf_list = dict_tl.dict_nn['Tagalog Noun TF-IDF'].tolist()\n",
    "jj_tl_tf_idf_list = dict_tl.dict_jj['Tagalog Adjective TF-IDF'].tolist()\n",
    "rb_tl_tf_idf_list = dict_tl.dict_rb['Tagalog Adverb TF-IDF'].tolist()\n",
    "cc_tl_tf_idf_list = dict_tl.dict_cc['Tagalog Conjunction TF-IDF'].tolist()\n",
    "pr_tl_tf_idf_list = dict_tl.dict_pr['Tagalog Preposition TF-IDF'].tolist()\n",
    "dt_tl_tf_idf_list = dict_tl.dict_dt['Tagalog Determiner TF-IDF'].tolist()\n",
    "\n",
    "\"\"\"\n",
    "    Count Vectors\n",
    "\"\"\"\n",
    "vb_il_tf_cnt_list = dict_tl.dict_vb['Ilokano Verb Count'].tolist()\n",
    "nn_il_tf_cnt_list = dict_tl.dict_nn['Ilokano Noun Count'].tolist()\n",
    "jj_il_tf_cnt_list = dict_tl.dict_jj['Ilokano Adjective Count'].tolist()\n",
    "rb_il_tf_cnt_list = dict_tl.dict_rb['Ilokano Adverb Count'].tolist()\n",
    "cc_il_tf_cnt_list = dict_tl.dict_cc['Ilokano Conjunction Count'].tolist()\n",
    "pr_il_tf_cnt_list = dict_tl.dict_pr['Ilokano Preposition Count'].tolist()\n",
    "dt_il_tf_cnt_list = dict_tl.dict_dt['Ilokano Determiner Count'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchial Dependence Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the SMT values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sum_tl(sen_poss_list, dict_source, not_in_sw, not_in_vb, not_in_nn, not_in_jj, not_in_rb, not_in_cc, not_in_pr, not_in_dt, not_tagged, sum_tf_idf_tl_list):\n",
    "    sp_index = 0 # sentence POS index\n",
    "    \n",
    "    for sen_poss in sen_poss_list:\n",
    "        # loop for getting the pos structure of every sentence\n",
    "        \"\"\"\n",
    "        sen_poss is a list of POS of a sentence\n",
    "        eg. ['VB', 'DT', 'NN', 'DT', 'NN']\n",
    "        \"\"\"\n",
    "        sen_translation = []\n",
    "        \n",
    "        sum_tf_idf_tl = 0\n",
    "        wp_index = 0 # word POS index\n",
    "        \n",
    "        for word_pos in sen_poss:\n",
    "            word = dict_source['Tokenized'][sp_index][wp_index]\n",
    "            # gets the word in every sentence\n",
    "            \n",
    "            # Matching Conditions    \n",
    "            # 1. SW\n",
    "            if word_pos == 'SW':\n",
    "                \"\"\"\n",
    "                if the POS of the word is 'SW'\n",
    "                \"\"\"\n",
    "                if word in dict_tl.sw_tl_list:\n",
    "                    \"\"\"\n",
    "                    if the word is in the Tagalog list of single words\n",
    "                    \"\"\"\n",
    "                    temp_index = dict_tl.sw_tl_list.index(word)\n",
    "                    \n",
    "                else:\n",
    "                    not_in_sw.append(word) # for debugging purposes\n",
    "                                \n",
    "            # 2. SW\n",
    "            elif word_pos == 'VB':\n",
    "                \"\"\"\n",
    "                if the POS of the word is 'VB'\n",
    "                \"\"\"\n",
    "                if word in dict_tl.vb_tl_list:\n",
    "                    \"\"\"\n",
    "                    if the word is in the Tagalog list of verbs\n",
    "                    \"\"\"\n",
    "                    temp_index = dict_tl.vb_tl_list.index(word)\n",
    "                    sum_tf_idf_tl += vb_tl_tf_idf_list[temp_index]\n",
    "                else:\n",
    "                    not_in_vb.append(word) # for debugging purposes\n",
    "            \n",
    "            # 3. NN\n",
    "            elif word_pos == 'NN':\n",
    "                \"\"\"\n",
    "                if the POS of the word is 'NN'\n",
    "                \"\"\"\n",
    "                if word in dict_tl.nn_tl_list:\n",
    "                    \"\"\"\n",
    "                    if the word is in the Tagalog list of nouns\n",
    "                    \"\"\"\n",
    "                    temp_index = dict_tl.nn_tl_list.index(word)\n",
    "                    sum_tf_idf_tl += nn_tl_tf_idf_list[temp_index]\n",
    "                else:\n",
    "                    not_in_nn.append(word) # for debugging purposes\n",
    "            \n",
    "            # 4. JJ\n",
    "            elif word_pos == 'JJ':\n",
    "                \"\"\"\n",
    "                if the POS of the word is 'JJ'\n",
    "                \"\"\"\n",
    "                if word in dict_tl.jj_tl_list:\n",
    "                    \"\"\"\n",
    "                    if the word is in the Tagalog list of nouns\n",
    "                    \"\"\"\n",
    "                    temp_index = dict_tl.jj_tl_list.index(word)\n",
    "                    sum_tf_idf_tl += jj_tl_tf_idf_list[temp_index]\n",
    "                else:\n",
    "                    not_in_jj.append(word) # for debugging purposes\n",
    "            \n",
    "            # 5. RB\n",
    "            elif word_pos == 'RB':\n",
    "                \"\"\"\n",
    "                if the POS of the word is 'RB'\n",
    "                \"\"\"\n",
    "                if word in dict_tl.rb_tl_list:\n",
    "                    \"\"\"\n",
    "                    if the word is in the Tagalog list of nouns\n",
    "                    \"\"\"\n",
    "                    temp_index = dict_tl.rb_tl_list.index(word)\n",
    "                    sum_tf_idf_tl += rb_tl_tf_idf_list[temp_index]\n",
    "                else:\n",
    "                    not_in_rb.append(word) # for debugging purposes\n",
    "                    \n",
    "            # 6. CC\n",
    "            elif word_pos == 'CC':\n",
    "                \"\"\"\n",
    "                if the POS of the word is 'CC'\n",
    "                \"\"\"\n",
    "                if word in dict_tl.cc_tl_list:\n",
    "                    \"\"\"\n",
    "                    if the word is in the Tagalog list of nouns\n",
    "                    \"\"\"\n",
    "                    temp_index = dict_tl.cc_tl_list.index(word)\n",
    "                    sum_tf_idf_tl += cc_tl_tf_idf_list[temp_index]\n",
    "                else:\n",
    "                    not_in_cc.append(word) # for debugging purposes\n",
    "                    \n",
    "            # 7. PR\n",
    "            elif word_pos == 'PR':\n",
    "                \"\"\"\n",
    "                if the POS of the word is 'CC'\n",
    "                \"\"\"\n",
    "                if word in dict_tl.pr_tl_list:\n",
    "                    \"\"\"\n",
    "                    if the word is in the Tagalog list of nouns\n",
    "                    \"\"\"\n",
    "                    temp_index = dict_tl.pr_tl_list.index(word)\n",
    "                    sum_tf_idf_tl += pr_tl_tf_idf_list[temp_index]\n",
    "                else:\n",
    "                    not_in_pr.append(word) # for debugging purposes\n",
    "            \n",
    "             # 8. DT\n",
    "            elif word_pos == 'DT':\n",
    "                \"\"\"\n",
    "                if the POS of the word is 'DT'\n",
    "                \"\"\"\n",
    "                if word in dict_tl.dt_tl_list:\n",
    "                    \"\"\"\n",
    "                    if the word is in the Tagalog list of nouns\n",
    "                    \"\"\"\n",
    "                    temp_index = dict_tl.dt_tl_list.index(word)\n",
    "                    sum_tf_idf_tl += dt_tl_tf_idf_list[temp_index]\n",
    "                else:\n",
    "                    not_in_dt.append(word) # for debugging purposes\n",
    "            \n",
    "            else:\n",
    "                not_tagged.append(word) # for debugging purposes\n",
    "                \n",
    "            wp_index += 1\n",
    "        \n",
    "        sum_tf_idf_tl_list.append(round(sum_tf_idf_tl, 5))\n",
    "        sp_index += 1\n",
    "        \n",
    "    return sum_tf_idf_tl_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating with SMT translation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_lm(ngram_data):\n",
    "    trans_ngram_data = []\n",
    "    for ngram_sen in ngram_data:\n",
    "        trans_ngram_sen = []\n",
    "        \n",
    "        for ngram in ngram_sen:\n",
    "            if ngram in tl_struct:\n",
    "                temp_index = tl_struct.index(ngram)\n",
    "                max_count = max(il_struct_count[temp_index])\n",
    "                trans_index = il_struct_count[temp_index].index(max_count)\n",
    "                trans_ngram = il_struct[temp_index][trans_index]\n",
    "                trans_ngram_sen.append(trans_ngram)\n",
    "            else:\n",
    "                trans_ngram_sen.append(ngram)\n",
    "                \n",
    "            # np_index += 1\n",
    "        \n",
    "        trans_ngram_data.append(trans_ngram_sen)\n",
    "        \n",
    "    return trans_ngram_data\n",
    "# end of function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_phrases = pd.read_csv('src/csv data/f_phrases.csv')\n",
    "il_phrases = f_phrases['Ilokano'].to_list()\n",
    "il_phrases = [remove_punct(word) for word in il_phrases]\n",
    "il_phrases = [tokenize(word) for word in il_phrases]\n",
    "\n",
    "tl_phrases = f_phrases['Tagalog'].to_list()\n",
    "tl_phrases = [remove_punct(word) for word in tl_phrases]\n",
    "tl_phrases = [tokenize(word) for word in tl_phrases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inFPhrases(word, word2, word3, tl_phrases):\n",
    "    inFPhrases = False\n",
    "    tl_phrase = []\n",
    "    w_used = 0\n",
    "    for phrase in tl_phrases:\n",
    "        length = len(phrase)\n",
    "        if length == 1:\n",
    "            if word == phrase[0]:\n",
    "                inFPhrases = True\n",
    "                tl_phrase = phrase\n",
    "                w_used = 1\n",
    "        if length == 2:\n",
    "            if word == phrase[0] and word2 == phrase[1]:\n",
    "                inFPhrases = True\n",
    "                tl_phrase = phrase\n",
    "                w_used = 2\n",
    "        if length == 3:\n",
    "            if word == phrase[0] and word2 == phrase[1] and word3 == phrase[2]:\n",
    "                inFPhrases = True\n",
    "                tl_phrase = phrase\n",
    "                w_used = 3\n",
    "                \n",
    "    return inFPhrases, tl_phrase, w_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smt import encapsulate, ngram_var\n",
    "\n",
    "def translate_smt(sen_poss_list, dict_source):\n",
    "    not_in_sw = []\n",
    "    not_in_vb = []\n",
    "    not_in_nn = []\n",
    "    not_in_jj = []\n",
    "    not_in_rb = []\n",
    "    not_in_cc = []\n",
    "    not_in_pr = []\n",
    "    not_in_dt = []\n",
    "    not_tagged = []\n",
    "    sum_tf_idf_tl_list = []\n",
    "\n",
    "    sum_tf_idf_tl_list = get_sum_tl(sen_poss_list, dict_source, not_in_sw, not_in_vb, not_in_nn, not_in_jj, not_in_rb, not_in_cc, not_in_pr, not_in_dt, not_tagged, sum_tf_idf_tl_list)\n",
    "    \n",
    "    encapsulate(sen_poss_list, ngram_var.fourgram_list, ngram_var.trigram_list, ngram_var.bigram_list, ngram_var.unigram_list, ngram_var.ngram_list, ngram_var.notencap_list, ngram_var.fourgram_count_sen, ngram_var.trigram_count_sen, ngram_var.bigram_count_sen, ngram_var.unigram_count_sen, ngram_var.notencap_count_sen)\n",
    "    \n",
    "    ngram_data = ngram_var.ngram_list\n",
    "    \n",
    "    trans_ngram_data = trans_lm(ngram_data)\n",
    "    \n",
    "    sp_index = 0 # sentence POS index\n",
    "    sen_translation_list = []\n",
    "    \n",
    "    for sen_poss in sen_poss_list:\n",
    "        # loop for getting the pos structure of every sentence\n",
    "        \"\"\"\n",
    "        sen_poss is a list of POS of a sentence\n",
    "        eg. ['VB', 'DT', 'NN', 'DT', 'NN']\n",
    "        \"\"\"\n",
    "        sen_translation = []\n",
    "        wp_index = 0\n",
    "        cur_wp_index = 0\n",
    "        \n",
    "        for word_pos in sen_poss:\n",
    "            if wp_index == cur_wp_index:\n",
    "                word = dict_source['Tokenized'][sp_index][wp_index]\n",
    "                # gets the word in every sentence\n",
    "                \n",
    "                try: \n",
    "                    word2 = dict_source['Tokenized'][sp_index][wp_index+1]\n",
    "                except:\n",
    "                    word2 = None\n",
    "                try:\n",
    "                    word3 = dict_source['Tokenized'][sp_index][wp_index+2]\n",
    "                except:\n",
    "                    word3 = None\n",
    "                    \n",
    "                ans = inFPhrases(word, word2, word3, tl_phrases)\n",
    "                inFPDict = ans[0]\n",
    "                tl_phrase = ans[1]\n",
    "                w_used = ans[2]                \n",
    "                \n",
    "                if inFPDict:\n",
    "                    \"\"\"\n",
    "                    if the word is in the list of Tagalog phrases\n",
    "                    \"\"\"\n",
    "                    p_index = tl_phrases.index(tl_phrase)\n",
    "                    il_phrase = il_phrases[p_index]\n",
    "                    for il_word in il_phrase:\n",
    "                        sen_translation.append(il_word)\n",
    "                    cur_wp_index = wp_index + w_used\n",
    "                    \n",
    "                else:\n",
    "                    cur_wp_index = wp_index + 1\n",
    "                    \n",
    "                    # Matching Conditions    \n",
    "                    # 1. SW\n",
    "                    if word_pos == 'SW':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'SW'\n",
    "                        \"\"\"\n",
    "                        if word in dict_tl.sw_tl_list:\n",
    "                            temp_index = dict_tl.sw_tl_list.index(word)\n",
    "                            if dict_tl.sw_il_list[temp_index][0] == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(dict_tl.sw_il_list[temp_index][0])\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                    \n",
    "                    # 2. VB\n",
    "                    elif word_pos == 'VB':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'VB'\n",
    "                        \"\"\"\n",
    "                        if word in dict_tl.vb_tl_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Tagalog list of verbs\n",
    "                            \"\"\"\n",
    "                            tl_index = dict_tl.vb_tl_list.index(word)\n",
    "                            max_tlidf = max(dict_tl.vb_tfidf_il_list[tl_index])\n",
    "                            il_index = dict_tl.vb_tfidf_il_list[tl_index].index(max_tlidf)\n",
    "                            il_word = dict_tl.vb_il_list[tl_index][il_index]\n",
    "                            \n",
    "                            if il_word == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(il_word)\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                    \n",
    "                    # 3. NN\n",
    "                    elif word_pos == 'NN':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'NN'\n",
    "                        \"\"\"\n",
    "                        if word in dict_tl.nn_tl_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Tagalog list of noun\n",
    "                            \"\"\"\n",
    "                            tl_index = dict_tl.nn_tl_list.index(word)\n",
    "                            max_tlidf = max(dict_tl.nn_tfidf_il_list[tl_index])\n",
    "                            il_index = dict_tl.nn_tfidf_il_list[tl_index].index(max_tlidf)\n",
    "                            il_word = dict_tl.nn_il_list[tl_index][il_index]\n",
    "                            \n",
    "                            if il_word == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(il_word)\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                    \n",
    "                    # 4. JJ\n",
    "                    elif word_pos == 'JJ':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'JJ'\n",
    "                        \"\"\"\n",
    "                        if word in dict_tl.jj_tl_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Tagalog list of adjectives\n",
    "                            \"\"\"\n",
    "                            tl_index = dict_tl.jj_tl_list.index(word)\n",
    "                            max_tlidf = max(dict_tl.jj_tfidf_il_list[tl_index])\n",
    "                            il_index = dict_tl.jj_tfidf_il_list[tl_index].index(max_tlidf)\n",
    "                            il_word = dict_tl.jj_il_list[tl_index][il_index]\n",
    "                            \n",
    "                            if il_word == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(il_word)\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                            \n",
    "                    # 5. RB\n",
    "                    elif word_pos == 'RB':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'RB'\n",
    "                        \"\"\"\n",
    "                        if word in dict_tl.rb_tl_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Tagalog list of adverbs\n",
    "                            \"\"\"\n",
    "                            tl_index = dict_tl.rb_tl_list.index(word)\n",
    "                            max_tlidf = max(dict_tl.rb_tfidf_il_list[tl_index])\n",
    "                            il_index = dict_tl.rb_tfidf_il_list[tl_index].index(max_tlidf)\n",
    "                            il_word = dict_tl.rb_il_list[tl_index][il_index]\n",
    "                            \n",
    "                            if il_word == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(il_word)\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                    \n",
    "                    # 6. CC\n",
    "                    elif word_pos == 'CC':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'CC'\n",
    "                        \"\"\"\n",
    "                        if word in dict_tl.cc_tl_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Tagalog list of conjunctions\n",
    "                            \"\"\"\n",
    "                            tl_index = dict_tl.cc_tl_list.index(word)\n",
    "                            max_tlidf = max(dict_tl.cc_tfidf_il_list[tl_index])\n",
    "                            il_index = dict_tl.cc_tfidf_il_list[tl_index].index(max_tlidf)\n",
    "                            il_word = dict_tl.cc_il_list[tl_index][il_index]\n",
    "                            \n",
    "                            if il_word == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(il_word)\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                            \n",
    "                    # 7. PR\n",
    "                    elif word_pos == 'PR':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'PR'\n",
    "                        \"\"\"\n",
    "                        if word in dict_tl.pr_tl_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Tagalog list of prepositions\n",
    "                            \"\"\"\n",
    "                            tl_index = dict_tl.pr_tl_list.index(word)\n",
    "                            max_tlidf = max(dict_tl.pr_tfidf_il_list[tl_index])\n",
    "                            il_index = dict_tl.pr_tfidf_il_list[tl_index].index(max_tlidf)\n",
    "                            il_word = dict_tl.pr_il_list[tl_index][il_index]\n",
    "                            \n",
    "                            if il_word == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(il_word)\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                            \n",
    "                    # 8. DT\n",
    "                    elif word_pos == 'DT':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'DT'\n",
    "                        \"\"\"\n",
    "                        if word in dict_tl.dt_tl_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Tagalog list of determiners\n",
    "                            \"\"\"\n",
    "                            tl_index = dict_tl.dt_tl_list.index(word)\n",
    "                            max_tlidf = max(dict_tl.dt_tfidf_il_list[tl_index])\n",
    "                            il_index = dict_tl.dt_tfidf_il_list[tl_index].index(max_tlidf)\n",
    "                            il_word = dict_tl.dt_il_list[tl_index][il_index]\n",
    "                            \n",
    "                            if il_word == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(il_word)\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                    \n",
    "                    else:\n",
    "                        sen_translation.append(word)\n",
    "\n",
    "            wp_index += 1\n",
    "        sp_index += 1\n",
    "        sen_translation_list.append(sen_translation)\n",
    "    \n",
    "    return sen_translation_list\n",
    "# end of function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening and processing the Source Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the file\n",
    "test_doc = open(\"src/text data/Bible_Tagalog.txt\", encoding='utf-8').read()\n",
    "target_op = open(\"src/text data/Bible_Ilokano.txt\", encoding='utf-8').read()\n",
    "\n",
    "parsed_source = test_doc.split(\"\\n\")\n",
    "# sample source\n",
    "parsed_source = parsed_source[0:100]\n",
    "\n",
    "cleaned_source = [remove_punct(word) for word in parsed_source]\n",
    "toklenized_source = [tokenize(word) for word in cleaned_source]\n",
    "dict_source = pd.DataFrame({'Tokenized': toklenized_source})\n",
    "pos_sen_list = tag(dict_source['Tokenized'])\n",
    "\n",
    "dict_source['POS'] = pos_sen_list\n",
    "sen_translation_list = translate_smt(dict_source['POS'], dict_source)\n",
    "temp_sen_list = combine_tokens(sen_translation_list)\n",
    "\n",
    "# Dictionary of the system output and the expected output and their scores\n",
    "dict_op_ex = pd.DataFrame({'System Output': temp_sen_list})\n",
    "\n",
    "parsed_expected_op = target_op.split(\"\\n\")\n",
    "parsed_expected_op = parsed_expected_op[0:100]\n",
    "cleaned_expected_op = [remove_punct(word) for word in parsed_expected_op]\n",
    "toklenized_expected_op = [tokenize(word) for word in cleaned_expected_op]\n",
    "combine_tokens_expected_op = combine_tokens(toklenized_expected_op)\n",
    "dict_op_ex['Target Output'] = combine_tokens_expected_op\n",
    "\n",
    "dict_op_ex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dict_op_ex_rec = dict_op_ex.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"src/json data/Tagalog to Ilokano/Hybrid Translator/dict_op_ex.json\", \"w\") as outfile:\n",
    "        json.dump(dict_op_ex_rec, outfile)\n",
    "    print(\"Successfully saved the file.\")\n",
    "except:\n",
    "    print(\"Error in saving the file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import scoring_bleu, scoring_ter\n",
    "\n",
    "ave_bleu = scoring_bleu(dict_op_ex)\n",
    "ave_ter = scoring_ter(dict_op_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average TER Score: \", ave_ter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd5e40cb983109c15fc1053f6f3e661cc97e68e07c1758cdbd2441c60186ce19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
