{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example-Based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of the Datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the Tagalog Part of Speech Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the tagalog POS dataset\n",
    "tl_pos_data = pd.read_json('src/json data/tl_pos.json')\n",
    "\n",
    "tl_doc_len = len(tl_pos_data)\n",
    "\n",
    "print('Number of documents in the dataset: {}'.format(tl_doc_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the Ilokano Part of Speech Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the ilokano POS dataset\n",
    "il_pos_data = pd.read_json('src/json data/il_pos.json')\n",
    "\n",
    "il_pos_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the Tagalog Part of Speech Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sen_poss = pd.DataFrame(tl_pos_data['POS'])\n",
    "\n",
    "dict_sen_poss.columns = ['Tagalog POS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the Ilokano Part of Speech "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sen_poss['Ilokano POS'] = il_pos_data['POS']\n",
    "\n",
    "dict_sen_poss.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verb Tagalog to Ilokano Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_sen_poss_list = dict_sen_poss['Tagalog POS']\n",
    "il_sen_poss_list = dict_sen_poss['Ilokano POS']\n",
    "\"\"\"\n",
    "putting the POS of the sentences in a list object\n",
    "\"\"\"\n",
    "\n",
    "dict_tl_il_sw = pd.DataFrame(columns=['Tagalog Single Words', 'Ilokano Single Words'])\n",
    "dict_tl_il_vb = pd.DataFrame(columns=['Tagalog Verb', 'Ilokano Verb'])\n",
    "dict_tl_il_nn = pd.DataFrame(columns=['Tagalog Noun', 'Ilokano Noun'])\n",
    "dict_tl_il_jj = pd.DataFrame(columns=['Tagalog Adjective', 'Ilokano Adjective'])\n",
    "dict_tl_il_rb = pd.DataFrame(columns=['Tagalog Adverb', 'Ilokano Adverb'])\n",
    "dict_tl_il_cc = pd.DataFrame(columns=['Tagalog Conjunction', 'Ilokano Conjunction'])\n",
    "dict_tl_il_pr = pd.DataFrame(columns=['Tagalog Preposition', 'Ilokano Preposition'])\n",
    "dict_tl_il_dt = pd.DataFrame(columns=['Tagalog Determiner', 'Ilokano Determiner'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending in the List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Verb List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_vb_list(tl_verb, tl_verb_list, il_verb, il_verb_list, curr_il_pos, next_il_pos, next2_il_pos, matched, sp_index, wp_index, il_verb_count_list, il_verb_count, tl_verb_count_list, tl_verb_sen):\n",
    "    if tl_verb not in tl_verb_list:\n",
    "        \"\"\"\n",
    "        if the verb is not in the list\n",
    "        \"\"\"\n",
    "        tl_verb_list.append(tl_verb)\n",
    "        \n",
    "        if tl_verb not in tl_verb_sen:\n",
    "            tl_verb_sen.append(tl_verb)\n",
    "            tl_verb_count_list.append(1)\n",
    "            \n",
    "        inDict = False\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the verb is in the list\n",
    "        \"\"\"\n",
    "        temp_index = tl_verb_list.index(tl_verb)\n",
    "        \n",
    "        if tl_verb not in tl_verb_sen:\n",
    "            tl_verb_sen.append(tl_verb)\n",
    "            tl_verb_count_list[temp_index] += 1\n",
    "        \n",
    "        inDict = True\n",
    "\n",
    "    \"\"\"\n",
    "    append the the verb in the tagalog verb\n",
    "    \"\"\"\n",
    "\n",
    "    if curr_il_pos == 'VB' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if VB : VB\n",
    "        if the Ilokano POS is a verb\n",
    "        \"\"\"\n",
    "        temp_verb = il_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        il_verb.append(temp_verb)\n",
    "        matched.append(wp_index)\n",
    "        \n",
    "    elif curr_il_pos == 'DT' and next_il_pos == 'VB' and wp_index not in matched:    \n",
    "        \"\"\"\n",
    "        if VB : DT VB\n",
    "        if the Ilokano POS is a determiner and the next POS is a verb\n",
    "        eg. Nilalang : ti Aramid\n",
    "        \"\"\"\n",
    "        temp_curr_verb = il_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        temp_next_verb = il_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        temp_verb = temp_curr_verb + ' ' + temp_next_verb\n",
    "        il_verb.append(temp_verb)\n",
    "        matched.append(wp_index)\n",
    "        matched.append(wp_index + 1) \n",
    "\n",
    "    elif curr_il_pos == 'NN' and next_il_pos == 'VB' and wp_index not in matched:    \n",
    "        \"\"\"\n",
    "        if VB : NN VB\n",
    "        if the Ilokano POS is a determiner and the next POS is a verb\n",
    "        \"\"\"\n",
    "        temp_verb = il_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        il_verb.append(temp_verb)\n",
    "        matched.append(wp_index + 1)\n",
    "        \n",
    "    elif curr_il_pos == 'DT' and next_il_pos == 'NN' and next2_il_pos == 'VB' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if VB DT NN : DT NN VB\n",
    "        if the Ilokano POS is a determiner and the next POS is a verb\n",
    "        \"\"\"\n",
    "        temp_verb = il_pos_data['Tokenized'][sp_index][wp_index + 2]\n",
    "        il_verb.append(temp_verb)\n",
    "        matched.append(wp_index + 2)\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if VB : Other POS\n",
    "        if the Ilokano POS is not a verb\n",
    "        \"\"\"\n",
    "        il_verb.append('None')\n",
    "        matched.append(wp_index)\n",
    "\n",
    "    if not inDict:\n",
    "        il_verb_list.append(il_verb)\n",
    "        il_verb_count.append(1)\n",
    "        il_verb_count_list.append(il_verb_count)\n",
    "    else:\n",
    "        if il_verb[0] not in il_verb_list[temp_index]:\n",
    "            il_verb_list[temp_index].append(il_verb[0])\n",
    "            il_verb_count_list[temp_index].append(1)\n",
    "        else:\n",
    "            temp_verb_index = il_verb_list[temp_index].index(il_verb[0])\n",
    "            il_verb_count_list[temp_index][temp_verb_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Noun List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_nn_list(tl_noun, tl_noun_list, il_noun, il_noun_list, curr_il_pos, next_il_pos, matched, sp_index, wp_index, il_noun_count_list, il_noun_count, tl_noun_count_list, tl_noun_sen):\n",
    "    if tl_noun not in tl_noun_list:\n",
    "        \"\"\"\n",
    "        if the noun is not in the list\n",
    "        \"\"\"\n",
    "        tl_noun_list.append(tl_noun)\n",
    "        \n",
    "        if tl_noun not in tl_noun_sen:\n",
    "            tl_noun_sen.append(tl_noun)\n",
    "            tl_noun_count_list.append(1)\n",
    "            \n",
    "        inDict = False\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the noun is in the list\n",
    "        \"\"\"\n",
    "        temp_index = tl_noun_list.index(tl_noun)\n",
    "        \n",
    "        if tl_noun not in tl_noun_sen:\n",
    "            tl_noun_sen.append(tl_noun)\n",
    "            tl_noun_count_list[temp_index] += 1\n",
    "        \n",
    "        inDict = True\n",
    "\n",
    "    \"\"\"\n",
    "    append the the noun in the tagalog noun\n",
    "    \"\"\"\n",
    "\n",
    "    if curr_il_pos == 'NN':\n",
    "        \"\"\"\n",
    "        if NN : NN\n",
    "        if the Ilokano POS is a noun\n",
    "        \"\"\"\n",
    "        temp_noun = il_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        il_noun.append(temp_noun)\n",
    "        matched.append(wp_index)\n",
    "        \n",
    "        \n",
    "    elif curr_il_pos == 'DT' and next_il_pos == 'NN':    \n",
    "        \"\"\"\n",
    "        if NN : DT NN\n",
    "        if the Ilokano POS is a determiner and the next POS is a noun\n",
    "        \"\"\"\n",
    "        temp_curr_noun = il_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        temp_next_noun = il_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        temp_noun = temp_curr_noun + ' ' + temp_next_noun\n",
    "        il_noun.append(temp_noun) \n",
    "        matched.append(wp_index + 1)\n",
    "          \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if NN : Other POS\n",
    "        if the Ilokano POS is not a noun\n",
    "        \"\"\"\n",
    "        il_noun.append('None')\n",
    "        matched.append(wp_index)\n",
    "\n",
    "    if not inDict:\n",
    "        il_noun_list.append(il_noun)\n",
    "        il_noun_count.append(1)\n",
    "        il_noun_count_list.append(il_noun_count)\n",
    "    else:\n",
    "        if il_noun[0] not in il_noun_list[temp_index]:\n",
    "            il_noun_list[temp_index].append(il_noun[0])\n",
    "            il_noun_count_list[temp_index].append(1)\n",
    "        else:\n",
    "            temp_noun_index = il_noun_list[temp_index].index(il_noun[0])\n",
    "            il_noun_count_list[temp_index][temp_noun_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Adjective List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_jj_list(tl_adj, tl_adj_list, il_adj, il_adj_list, curr_il_pos, next_il_pos, next2_il_pos, matched, sp_index, wp_index, il_adj_count_list, il_adj_count, tl_adj_count_list, tl_adj_sen):\n",
    "    if tl_adj not in tl_adj_list:\n",
    "        \"\"\"\n",
    "        if the adj is not in the list\n",
    "        \"\"\"\n",
    "        tl_adj_list.append(tl_adj)\n",
    "        \n",
    "        if tl_adj not in tl_adj_sen:\n",
    "            tl_adj_sen.append(tl_adj)\n",
    "            tl_adj_count_list.append(1)\n",
    "        \n",
    "        inDict = False\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the adj is in the list\n",
    "        \"\"\"\n",
    "        temp_index = tl_adj_list.index(tl_adj)\n",
    "        \n",
    "        if tl_adj not in tl_adj_sen:\n",
    "            tl_adj_sen.append(tl_adj)\n",
    "            tl_adj_count_list[temp_index] += 1\n",
    "        \n",
    "        inDict = True\n",
    "\n",
    "    \"\"\"\n",
    "    append the the adj in the tagalog adj\n",
    "    \"\"\"\n",
    "\n",
    "    if curr_il_pos == 'JJ':\n",
    "        \"\"\"\n",
    "        if JJ : JJ\n",
    "        if the Ilokano POS is an adj\n",
    "        \"\"\"\n",
    "        temp_adj = il_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        il_adj.append(temp_adj)\n",
    "        matched.append(wp_index)\n",
    "        \n",
    "    elif curr_il_pos == 'DT' and next_il_pos == 'JJ':    \n",
    "        \"\"\"\n",
    "        if JJ : DT JJ\n",
    "        if the Ilokano POS is a determiner and the next POS is an adj\n",
    "        eg. mabubuting : ken naimbag\n",
    "        \"\"\"\n",
    "        temp_curr_adj = il_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        temp_next_adj = il_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        temp_adj = temp_curr_adj + ' ' + temp_next_adj\n",
    "        il_adj.append(temp_adj) \n",
    "        matched.append(wp_index + 1)\n",
    "\n",
    "    else:\n",
    "        \"\"\"\n",
    "        if JJ : Other POS\n",
    "        if the Ilokano POS is not an adj\n",
    "        \"\"\"\n",
    "        il_adj.append('None')\n",
    "        matched.append(wp_index)\n",
    "\n",
    "    if not inDict:\n",
    "        il_adj_list.append(il_adj)\n",
    "        il_adj_count.append(1)\n",
    "        il_adj_count_list.append(il_adj_count)\n",
    "    else:\n",
    "        if il_adj[0] not in il_adj_list[temp_index]:\n",
    "            il_adj_list[temp_index].append(il_adj[0])\n",
    "            il_adj_count_list[temp_index].append(1)\n",
    "        else:\n",
    "            temp_adj_index = il_adj_list[temp_index].index(il_adj[0])\n",
    "            il_adj_count_list[temp_index][temp_adj_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Adverb List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_rb_list(tl_adv, tl_adv_list, il_adv, il_adv_list, curr_il_pos, next_il_pos, next2_il_pos, next3_il_pos, prev_il_pos, matched, sp_index, wp_index, il_adv_count_list, il_adv_count, tl_adv_count_list, tl_adv_sen):\n",
    "    if tl_adv not in tl_adv_list:\n",
    "        \"\"\"\n",
    "        if the adverb is not in the list\n",
    "        \"\"\"\n",
    "        tl_adv_list.append(tl_adv)\n",
    "        \n",
    "        if tl_adv_list not in tl_adv_sen:\n",
    "            tl_adv_sen.append(tl_adv)\n",
    "            tl_adv_count_list.append(1)\n",
    "        \n",
    "        inDict = False\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the adverb is in the list\n",
    "        \"\"\"\n",
    "        temp_index = tl_adv_list.index(tl_adv)\n",
    "        \n",
    "        if tl_adv_list not in tl_adv_sen:\n",
    "            tl_adv_sen.append(tl_adv)\n",
    "            tl_adv_count_list[temp_index] += 1\n",
    "            \n",
    "        inDict = True\n",
    "\n",
    "    \"\"\"\n",
    "    append the the verb in the tagalog verb\n",
    "    \"\"\"\n",
    "\n",
    "    if curr_il_pos == 'RB':\n",
    "        \"\"\"\n",
    "        if RB : RB\n",
    "        if the Ilokano POS is a adverb\n",
    "        \"\"\"\n",
    "        temp_adverb = il_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        il_adv.append(temp_adverb)\n",
    "        matched.append(wp_index)\n",
    "        \n",
    "    elif curr_il_pos == 'DT' and next_il_pos == 'RB':    \n",
    "        \"\"\"\n",
    "        if RB : DT RB\n",
    "        \"\"\"\n",
    "        temp_curr_adverb = il_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        temp_next_adverb = il_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        temp_adverb = temp_curr_adverb + ' ' + temp_next_adverb\n",
    "        il_adv.append(temp_adverb) \n",
    "        matched.append(wp_index + 1)\n",
    "  \n",
    "        \n",
    "    elif curr_il_pos == 'DT' and next_il_pos == 'NN' and next2_il_pos == 'DT' and next3_il_pos == 'RB' :  \n",
    "        \"\"\"\n",
    "        if RB : DT NN DT RB\n",
    "        \n",
    "        \"\"\"\n",
    "        temp_adverb = il_pos_data['Tokenized'][sp_index][wp_index + 3]\n",
    "        il_adv.append(temp_adverb)\n",
    "        matched.append(wp_index + 3)\n",
    "        \n",
    "    elif curr_il_pos == 'DT' and prev_il_pos == 'RB':\n",
    "        \"\"\"\n",
    "        if RB : DT with RB behind DT\n",
    "        \n",
    "        \"\"\"\n",
    "        temp_adverb = il_pos_data['Tokenized'][sp_index][wp_index - 1]\n",
    "        il_adv.append(temp_adverb)\n",
    "        matched.append(wp_index - 1)\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if RB : Other POS\n",
    "        if the Ilokano POS is not a adverb\n",
    "        \"\"\"\n",
    "        il_adv.append('None')\n",
    "        matched.append(wp_index)\n",
    "\n",
    "    if not inDict:\n",
    "        il_adv_list.append(il_adv)\n",
    "        il_adv_count.append(1)\n",
    "        il_adv_count_list.append(il_adv_count)\n",
    "    else:\n",
    "        if il_adv[0] not in il_adv_list[temp_index]:\n",
    "            il_adv_list[temp_index].append(il_adv[0])\n",
    "            il_adv_count_list[temp_index].append(1)\n",
    "        else:\n",
    "            temp_adj_index = il_adv_list[temp_index].index(il_adv[0])\n",
    "            il_adv_count_list[temp_index][temp_adj_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Conjunction List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_cc_list(tl_conj, tl_conj_list, il_conj, il_conj_list, curr_il_pos, matched, sp_index, wp_index, il_conj_count_list, il_conj_count, tl_conj_count_list, tl_conj_sen):\n",
    "    if tl_conj not in tl_conj_list:\n",
    "        \"\"\"\n",
    "        if the conj is not in the list\n",
    "        \"\"\"\n",
    "        tl_conj_list.append(tl_conj)\n",
    "        \n",
    "        if tl_conj not in tl_conj_sen:\n",
    "            tl_conj_sen.append(tl_conj)\n",
    "            tl_conj_count_list.append(1)\n",
    "        \n",
    "        inDict = False\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the conj is in the list\n",
    "        \"\"\"\n",
    "        temp_index = tl_conj_list.index(tl_conj)\n",
    "        \n",
    "        if tl_conj not in tl_conj_sen:\n",
    "            tl_conj_sen.append(tl_conj)\n",
    "            tl_conj_count_list[temp_index] += 1\n",
    "        \n",
    "        inDict = True\n",
    "\n",
    "    \"\"\"\n",
    "    append the the conj in the tagalog conj\n",
    "    \"\"\"\n",
    "\n",
    "    if curr_il_pos == 'CC':\n",
    "        \"\"\"\n",
    "        if CC : CC\n",
    "        if the Ilokano POS is a conj\n",
    "        \"\"\"\n",
    "        temp_conj = il_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        il_conj.append(temp_conj)\n",
    "        matched.append(wp_index)\n",
    "          \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if CC : Other POS\n",
    "        if the Ilokano POS is not a conj\n",
    "        \"\"\"\n",
    "        il_conj.append('None')\n",
    "        matched.append(wp_index)\n",
    "\n",
    "    if not inDict:\n",
    "        il_conj_list.append(il_conj)\n",
    "        il_conj_count.append(1)\n",
    "        il_conj_count_list.append(il_conj_count)\n",
    "    else:\n",
    "        if il_conj[0] not in il_conj_list[temp_index]:\n",
    "            il_conj_list[temp_index].append(il_conj[0])\n",
    "            il_conj_count_list[temp_index].append(1)\n",
    "        else:\n",
    "            temp_conj_index = il_conj_list[temp_index].index(il_conj[0])\n",
    "            il_conj_count_list[temp_index][temp_conj_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Preposition List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_pr_list(tl_prepo, tl_prepo_list, il_prepo, il_prepo_list, curr_il_pos, next_il_pos, next2_il_pos, matched, sp_index, wp_index, il_prepo_count_list, il_prepo_count, tl_prepo_count_list, tl_prepo_sen):\n",
    "    if tl_prepo not in tl_prepo_list:\n",
    "        \"\"\"\n",
    "        if the preposition is not in the list\n",
    "        \"\"\"\n",
    "        tl_prepo_list.append(tl_prepo)\n",
    "        \n",
    "        if tl_prepo not in tl_prepo_sen:\n",
    "            tl_prepo_sen.append(tl_prepo)\n",
    "            tl_prepo_count_list.append(1)\n",
    "                \n",
    "        inDict = False\n",
    "    \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the preposition is in the list\n",
    "        \"\"\"\n",
    "        temp_index = tl_prepo_list.index(tl_prepo)   \n",
    "        \n",
    "        if tl_prepo not in tl_prepo_sen:\n",
    "            tl_prepo_sen.append(tl_prepo)\n",
    "            tl_prepo_count_list[temp_index] += 1\n",
    "             \n",
    "        inDict = True\n",
    "    \n",
    "    \"\"\"\n",
    "    append the the verb in the tagalog verb\n",
    "    \"\"\"\n",
    "    \n",
    "    if curr_il_pos == 'PR' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if PR : PR\n",
    "        if the Ilokano POS is a verb\n",
    "        \"\"\"\n",
    "        temp_prepo = il_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        il_prepo.append(temp_prepo)\n",
    "        matched.append(wp_index)\n",
    "    \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if VB : Other POS\n",
    "        if the Ilokano POS is not a verb\n",
    "        \"\"\"\n",
    "        il_prepo.append('None')\n",
    "        matched.append(wp_index)\n",
    "    \n",
    "    if not inDict:\n",
    "        il_prepo_list.append(il_prepo)\n",
    "        il_prepo_count.append(1)\n",
    "        il_prepo_count_list.append(il_prepo_count)\n",
    "    else:\n",
    "        if il_prepo[0] not in il_prepo_list[temp_index]:\n",
    "            il_prepo_list[temp_index].append(il_prepo[0])\n",
    "            il_prepo_count_list[temp_index].append(1)\n",
    "        else:\n",
    "            temp_prepo_index = il_prepo_list[temp_index].index(il_prepo[0])\n",
    "            il_prepo_count_list[temp_index][temp_prepo_index] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Determiner List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_dt_list(tl_dt, tl_dt_list, il_dt, il_dt_list, curr_il_pos, next_il_pos, next2_il_pos, matched, sp_index, wp_index, il_dt_count_list, il_dt_count, tl_dt_count_list, tl_dt_sen):\n",
    "    if tl_dt not in tl_dt_list:\n",
    "        \"\"\"\n",
    "        if the preposition is not in the list\n",
    "        \"\"\"\n",
    "        tl_dt_list.append(tl_dt)\n",
    "        \n",
    "        if tl_dt not in tl_dt_sen:\n",
    "            tl_dt_sen.append(tl_dt)\n",
    "            tl_dt_count_list.append(1)\n",
    "        \n",
    "        inDict = False\n",
    "    \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the preposition is in the list\n",
    "        \"\"\"\n",
    "        temp_index = tl_dt_list.index(tl_dt)\n",
    "        \n",
    "        if tl_dt not in tl_dt_sen:\n",
    "            tl_dt_sen.append(tl_dt)\n",
    "            tl_dt_count_list[temp_index] += 1\n",
    "        \n",
    "        inDict = True\n",
    "    \n",
    "    \"\"\"\n",
    "    append the the verb in the tagalog verb\n",
    "    \"\"\"\n",
    "    \n",
    "    if curr_il_pos == 'DT' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if PR : PR\n",
    "        if the Ilokano POS is a verb\n",
    "        \"\"\"\n",
    "        temp_prepo = il_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        il_dt.append(temp_prepo)\n",
    "        matched.append(wp_index)\n",
    "    \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if VB : Other POS\n",
    "        if the Ilokano POS is not a verb\n",
    "        \"\"\"\n",
    "        il_dt.append('None')\n",
    "        matched.append(wp_index)\n",
    "        \n",
    "    if not inDict:\n",
    "        il_dt_list.append(il_dt)\n",
    "        il_dt_count.append(1)\n",
    "        il_dt_count_list.append(il_dt_count)\n",
    "    else:\n",
    "        if il_dt[0] not in il_dt_list[temp_index]:\n",
    "            il_dt_list[temp_index].append(il_dt[0])\n",
    "            il_dt_count_list[temp_index].append(1)\n",
    "        else:\n",
    "            temp_dt_index = il_dt_list[temp_index].index(il_dt[0])\n",
    "            il_dt_count_list[temp_index][temp_dt_index] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_idf(tl_count_list):\n",
    "    tl_idf = []\n",
    "    for tl_count in tl_count_list:\n",
    "        temp_quo = tl_doc_len/tl_count\n",
    "        tl_idf.append(abs(math.log10(temp_quo)))\n",
    "        \n",
    "    return tl_idf\n",
    "# end of get_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tagalog to Ilokano Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "wp_index = None # word position index\n",
    "\n",
    "\"\"\"\n",
    "instantiating the verb lists\n",
    "\"\"\"\n",
    "\n",
    "def match_tl_il_pos():\n",
    "    \"\"\"\n",
    "    This function matches the POS of the sentences in the Tagalog and Ilokano datasets\n",
    "    \"\"\"\n",
    "    tl_sw_list = []\n",
    "    il_sw_list = []\n",
    "    tl_verb_list = []\n",
    "    il_verb_list = []\n",
    "    tl_noun_list = []\n",
    "    il_noun_list = []\n",
    "    tl_adj_list = []\n",
    "    il_adj_list = []\n",
    "    tl_adv_list = []\n",
    "    il_adv_list = []\n",
    "    tl_conj_list = []\n",
    "    il_conj_list = []\n",
    "    tl_prepo_list = []\n",
    "    il_prepo_list = []\n",
    "    tl_dt_list = []\n",
    "    il_dt_list = []\n",
    "    tl_to_il_verb_list = []\n",
    "    sp_index = 0\n",
    "    \"\"\"\n",
    "    instantiating the verb lists\n",
    "    \"\"\"\n",
    "    \n",
    "    il_verb_count_list = []\n",
    "    il_noun_count_list = []\n",
    "    il_adj_count_list = []\n",
    "    il_adv_count_list = []\n",
    "    il_conj_count_list = []\n",
    "    il_prepo_count_list = []\n",
    "    il_dt_count_list = []\n",
    "    \n",
    "    tl_verb_count_list = []\n",
    "    tl_noun_count_list = []\n",
    "    tl_adj_count_list = []\n",
    "    tl_adv_count_list = []\n",
    "    tl_conj_count_list = []\n",
    "    tl_prepo_count_list = []\n",
    "    tl_dt_count_list = []\n",
    "    \n",
    "    for tl_sen_pos in tl_sen_poss_list:\n",
    "        # loop for getting the pos structure of every sentence\n",
    "        \"\"\"\n",
    "        tl_sen is a list of POS of a sentence\n",
    "        eg. ['VB', 'DT', 'NN', 'DT', 'NN']\n",
    "        \"\"\"\n",
    "        matched = []\n",
    "        il_sen = il_sen_poss_list[sp_index]\n",
    "    \n",
    "        wp_index = 0\n",
    "        \"\"\"\n",
    "        instantiating the variables\n",
    "        \"\"\"\n",
    "        \n",
    "        tl_verb_sen = []\n",
    "        tl_noun_sen = []\n",
    "        tl_adj_sen = []\n",
    "        tl_adv_sen = []\n",
    "        tl_conj_sen = []\n",
    "        tl_prepo_sen = []\n",
    "        tl_dt_sen = []\n",
    "        \n",
    "        for tl_word_pos in tl_sen_pos:\n",
    "            # loop for each pos in a sentence\n",
    "            \"\"\"\n",
    "            tl_word_pos is a POS of a word\n",
    "            eg. 'VB'\n",
    "            \"\"\"\n",
    "            \n",
    "            il_verb = []\n",
    "            il_noun = []\n",
    "            il_adj = []\n",
    "            il_adv = []\n",
    "            il_conj = []\n",
    "            il_prepo = []\n",
    "            il_dt = []\n",
    "            \n",
    "            il_verb_count = []\n",
    "            il_noun_count = []\n",
    "            il_adj_count = []\n",
    "            il_adv_count = []\n",
    "            il_conj_count = []\n",
    "            il_prepo_count = []\n",
    "            il_dt_count = []\n",
    "            \n",
    "            tl_word = tl_pos_data['Tokenized'][sp_index][wp_index]\n",
    "            # gets the word in every sentence\n",
    "            \n",
    "            try:\n",
    "                curr_il_pos = il_sen[wp_index] # ti\n",
    "            except IndexError:\n",
    "                curr_il_pos = 'None'\n",
    "            try:\n",
    "                next_il_pos = il_sen[wp_index + 1]\n",
    "            except IndexError:\n",
    "                next_il_pos = 'None'\n",
    "            try:\n",
    "                next2_il_pos = il_sen[wp_index + 2]\n",
    "            except IndexError:\n",
    "                next2_il_pos = 'None'\n",
    "            try:\n",
    "                next3_il_pos = il_sen[wp_index + 3]\n",
    "            except IndexError:\n",
    "                next3_il_pos = 'None'\n",
    "            try:\n",
    "                prev_il_pos = il_sen[wp_index - 1]\n",
    "                if (wp_index - 1) < 0:\n",
    "                    prev_il_pos = 'None'\n",
    "            except IndexError:\n",
    "                prev_il_pos = 'None'\n",
    "            \"\"\"\n",
    "            getting the current, next, and previous POS in the sentence\n",
    "            \"\"\"\n",
    "            \n",
    "            # Matching Conditions\n",
    "            \n",
    "            # 1. SW\n",
    "            if tl_word_pos == 'SW':\n",
    "                \"\"\"\n",
    "                if SW : SW\n",
    "                if the Tagalog POS is a SW\n",
    "                \"\"\"\n",
    "                il_word = il_pos_data['Tokenized'][sp_index]\n",
    "                tl_sw_list.append(tl_word)\n",
    "                il_sw_list.append(il_word)\n",
    "            \n",
    "            # 2. VB\n",
    "            if tl_word_pos == 'VB':\n",
    "                \"\"\"\n",
    "                Verb Matching\n",
    "                if the POS is a verb, append the index of the verb to the verb list\n",
    "                \"\"\"\n",
    "                \n",
    "                append_vb_list(tl_word, tl_verb_list, il_verb, il_verb_list, curr_il_pos, next_il_pos, next2_il_pos, matched, sp_index, wp_index, il_verb_count_list, il_verb_count, tl_verb_count_list, tl_verb_sen)\n",
    "                \n",
    "            # 3. NN\n",
    "            if tl_word_pos == 'NN':\n",
    "                \"\"\"\n",
    "                Noun Matching\n",
    "                if the POS is a noun, append the index of the noun to the noun list\n",
    "                \"\"\"\n",
    "                append_nn_list(tl_word, tl_noun_list, il_noun, il_noun_list, curr_il_pos, next_il_pos, matched, sp_index, wp_index, il_noun_count_list, il_noun_count, tl_noun_count_list, tl_noun_sen)\n",
    "\n",
    "            # 4. JJ\n",
    "            if tl_word_pos == 'JJ':\n",
    "                \"\"\"\n",
    "                Adj Matching\n",
    "                if the POS is a adj, append the index of the adj to the adj list\n",
    "                \"\"\"\n",
    "                append_jj_list(tl_word, tl_adj_list, il_adj, il_adj_list, curr_il_pos, next_il_pos, next2_il_pos, matched, sp_index, wp_index, il_adj_count_list, il_adj_count, tl_adj_count_list, tl_adj_sen)\n",
    "            \n",
    "            # 5. RB\n",
    "            if tl_word_pos == 'RB':\n",
    "                \"\"\"\n",
    "                Adverb Matching\n",
    "                if the POS is a adverb, append the index of the adverb to the adverb list\n",
    "                \"\"\"\n",
    "                append_rb_list(tl_word, tl_adv_list, il_adv, il_adv_list, curr_il_pos, next_il_pos, next2_il_pos, next3_il_pos, prev_il_pos, matched, sp_index, wp_index, il_adv_count_list, il_adv_count, tl_adv_count_list, tl_adv_sen)\n",
    "            \n",
    "            # 6. CC\n",
    "            if tl_word_pos == 'CC':\n",
    "                \"\"\"\n",
    "                Conjunction Matching\n",
    "                if the POS is a conjunction, append the index of the conjunction to the conjunction list\n",
    "                \"\"\"\n",
    "                append_cc_list(tl_word, tl_conj_list, il_conj, il_conj_list, curr_il_pos, matched, sp_index, wp_index, il_conj_count_list, il_conj_count, tl_conj_count_list, tl_conj_sen)\n",
    "            \n",
    "            # 7. PR\n",
    "            if tl_word_pos == 'PR':\n",
    "                \"\"\"\n",
    "                Preposition Matching\n",
    "                if the POS is a preposition, append the index of the conjunction to the conjunction list\n",
    "                \"\"\"\n",
    "                append_pr_list(tl_word, tl_prepo_list, il_prepo, il_prepo_list, curr_il_pos, next_il_pos, next2_il_pos, matched, sp_index, wp_index, il_prepo_count_list, il_prepo_count, tl_prepo_count_list, tl_prepo_sen)\n",
    "            \n",
    "            # 8. DT\n",
    "            if tl_word_pos == 'DT':\n",
    "                \"\"\"\n",
    "                Determiner Matching\n",
    "                if the POS is a determiner, append the index of the conjunction to the conjunction list\n",
    "                \"\"\"\n",
    "                append_dt_list(tl_word, tl_dt_list, il_dt, il_dt_list, curr_il_pos, next_il_pos, next2_il_pos, matched, sp_index, wp_index, il_dt_count_list, il_dt_count, tl_dt_count_list, tl_dt_sen)\n",
    "            \n",
    "                          \n",
    "            wp_index += 1     \n",
    "        sp_index += 1\n",
    "    \n",
    "    tl_verb_idf = get_idf(tl_verb_count_list)\n",
    "    tl_noun_idf = get_idf(tl_noun_count_list)\n",
    "    tl_adj_idf = get_idf(tl_adj_count_list)\n",
    "    tl_adv_idf = get_idf(tl_adv_count_list)\n",
    "    tl_conj_idf = get_idf(tl_conj_count_list)\n",
    "    tl_prepo_idf = get_idf(tl_prepo_count_list)\n",
    "    tl_dt_idf = get_idf(tl_dt_count_list)\n",
    "    \n",
    "    dict_tl_il_sw['Tagalog Single Words'] = tl_sw_list\n",
    "    dict_tl_il_sw['Ilokano Single Words'] = il_sw_list\n",
    "    \n",
    "    dict_tl_il_vb['Tagalog Verb'] = tl_verb_list\n",
    "    dict_tl_il_vb['Tagalog Verb IDF'] = tl_verb_idf\n",
    "    dict_tl_il_vb['Ilokano Verb'] = il_verb_list\n",
    "    dict_tl_il_vb['Ilokano Verb Count'] = il_verb_count_list\n",
    "    \n",
    "    dict_tl_il_nn['Tagalog Noun'] = tl_noun_list\n",
    "    dict_tl_il_nn['Tagalog Noun IDF'] = tl_noun_idf\n",
    "    dict_tl_il_nn['Ilokano Noun'] = il_noun_list\n",
    "    dict_tl_il_nn['Ilokano Noun Count'] = il_noun_count_list\n",
    "    \n",
    "    dict_tl_il_jj['Tagalog Adjective'] = tl_adj_list\n",
    "    dict_tl_il_jj['Tagalog Adjective IDF'] = tl_adj_idf\n",
    "    dict_tl_il_jj['Ilokano Adjective'] = il_adj_list\n",
    "    dict_tl_il_jj['Ilokano Adjective Count'] = il_adj_count_list\n",
    "    \n",
    "    dict_tl_il_rb['Tagalog Adverb'] = tl_adv_list\n",
    "    dict_tl_il_rb['Tagalog Adverb IDF'] = tl_adv_idf\n",
    "    dict_tl_il_rb['Ilokano Adverb'] = il_adv_list\n",
    "    dict_tl_il_rb['Ilokano Adverb Count'] = il_adv_count_list\n",
    "    \n",
    "    dict_tl_il_cc['Tagalog Conjunction'] = tl_conj_list\n",
    "    dict_tl_il_cc['Tagalog Conjunction IDF'] = tl_conj_idf\n",
    "    dict_tl_il_cc['Ilokano Conjunction'] = il_conj_list\n",
    "    dict_tl_il_cc['Ilokano Conjunction Count'] = il_conj_count_list\n",
    "    \n",
    "    dict_tl_il_pr['Tagalog Preposition'] = tl_prepo_list\n",
    "    dict_tl_il_pr['Tagalog Preposition IDF'] = tl_prepo_idf\n",
    "    dict_tl_il_pr['Ilokano Preposition'] = il_prepo_list\n",
    "    dict_tl_il_pr['Ilokano Preposition Count'] = il_prepo_count_list\n",
    "    \n",
    "    dict_tl_il_dt['Tagalog Determiner'] = tl_dt_list\n",
    "    dict_tl_il_dt['Tagalog Determiner IDF'] = tl_dt_idf\n",
    "    dict_tl_il_dt['Ilokano Determiner'] = il_dt_list\n",
    "    dict_tl_il_dt['Ilokano Determiner Count'] = il_dt_count_list\n",
    "    \n",
    "match_tl_il_pos()\n",
    "# dict_tl_il_sw.head()\n",
    "# dict_tl_il_vb.head(50)\n",
    "# dict_tl_il_nn.head(50)\n",
    "# dict_tl_il_jj.head(50)\n",
    "# dict_tl_il_rb.head(50)\n",
    "# dict_tl_il_cc.head(50)\n",
    "# dict_tl_il_pr.head(50)\n",
    "dict_tl_il_dt.head(50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the dictionary in the json file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Single Word Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dict_sw = dict_tl_il_sw.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"src/json data/Example-Based/dict_sw.json\", \"w\") as outfile:\n",
    "        json.dump(dict_sw, outfile)\n",
    "    print(\"successfully saved the dict_sw.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_sw.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Verb Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_vb = dict_tl_il_vb.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"src/json data/Example-Based/dict_vb.json\", \"w\") as outfile:\n",
    "        json.dump(dict_vb, outfile)\n",
    "    print(\"successfully saved the dict_vb.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_vb.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Noun Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_nn = dict_tl_il_nn.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"src/json data/Example-Based/dict_nn.json\", \"w\") as outfile:\n",
    "        json.dump(dict_nn, outfile)\n",
    "    print(\"successfully saved the dict_nn.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_nn.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Adjective Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_jj = dict_tl_il_jj.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"src/json data/Example-Based/dict_jj.json\", \"w\") as outfile:\n",
    "        json.dump(dict_jj, outfile)\n",
    "    print(\"successfully saved the dict_jj.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_jj.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Adverb Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rb = dict_tl_il_rb.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"src/json data/Example-Based/dict_rb.json\", \"w\") as outfile:\n",
    "        json.dump(dict_rb, outfile)\n",
    "    print(\"successfully saved the dict_rb.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_rb.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Conjunction Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cc = dict_tl_il_cc.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"src/json data/Example-Based/dict_cc.json\", \"w\") as outfile:\n",
    "        json.dump(dict_cc, outfile)\n",
    "    print(\"successfully saved the dict_cc.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_cc.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Preposition Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pr = dict_tl_il_pr.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"src/json data/Example-Based/dict_pr.json\", \"w\") as outfile:\n",
    "        json.dump(dict_pr, outfile)\n",
    "    print(\"successfully saved the dict_pr.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_pr.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Determiner Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dt = dict_tl_il_dt.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"src/json data/Example-Based/dict_dt.json\", \"w\") as outfile:\n",
    "        json.dump(dict_dt, outfile)\n",
    "    print(\"successfully saved the dict_dt.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_dt.json file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd5e40cb983109c15fc1053f6f3e661cc97e68e07c1758cdbd2441c60186ce19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
