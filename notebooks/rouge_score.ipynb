{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUGE SCORE (Recall, Precision, F1 Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compute_rouge_score(src_text_list, tgt_op_list, sys_op_list, filename):\n",
    "    correct_candidate_words = 0\n",
    "    total_reference_words = 0\n",
    "    correct_reference_words = 0\n",
    "    total_candidate_words = 0\n",
    "    recall_sum = 0\n",
    "    precision_sum = 0\n",
    "    f1_sum = 0\n",
    "    csv_frame = pd.DataFrame(columns=[\"INPUT\", \"REFERENCE\", \"MACHINE_TRANSLATION\", \"CANDIDATE_IN_REF\", \"TOTAL_IN_REF\", \"RECALL\", \"REF_IN_CANDIDATE\", \"TOTAL_IN_CANDIDATE\", \"PRECISION\", \"F1_SCORE\"])\n",
    "\n",
    "    for index, target_op in enumerate(tgt_op_list):\n",
    "        source_text = src_text_list[index]\n",
    "        system_op = sys_op_list[index]\n",
    "\n",
    "        reference_words = target_op.split()\n",
    "        candidate_words = system_op.split()\n",
    "\n",
    "        # Increment the number of correctly identified candidate words in the reference\n",
    "        correct_candidate_words = len(set(candidate_words) & set(reference_words))\n",
    "        \n",
    "        # Increment the total number of words in the reference\n",
    "        total_reference_words = len(reference_words)\n",
    "        \n",
    "        # Calculate the number of correctly identified reference words in the candidate\n",
    "        correct_reference_words = len(set(candidate_words) & set(reference_words))\n",
    "        \n",
    "        # Calculate the total number of words in the candidate\n",
    "        total_candidate_words = len(candidate_words)\n",
    "\n",
    "        # Calculate the recall score\n",
    "        recall = correct_candidate_words / total_reference_words    \n",
    "        \n",
    "        # Calculate the precision score\n",
    "        precision = correct_reference_words / total_candidate_words\n",
    "        \n",
    "        #Calculate F1 Score\n",
    "        if precision == 0 or recall == 0:\n",
    "            f1_score = 0\n",
    "        else:\n",
    "            f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "        recall_sum += recall\n",
    "        precision_sum += precision\n",
    "        f1_sum += f1_score\n",
    "\n",
    "        csv_frame = csv_frame.append({\"INPUT\": source_text, \"REFERENCE\": target_op, \"MACHINE_TRANSLATION\": system_op, \"CANDIDATE_IN_REF\": correct_candidate_words, \"TOTAL_IN_REF\": total_reference_words, \"RECALL\": recall, \"REF_IN_CANDIDATE\": correct_reference_words, \"TOTAL_IN_CANDIDATE\": total_candidate_words, \"PRECISION\": precision, \"F1_SCORE\": f1_score}, ignore_index=True)\n",
    "        \n",
    "    # Calculate the average recall, precision, and F1 scores\n",
    "    average_recall = recall_sum / len(src_text_list)\n",
    "    average_precision = precision_sum / len(src_text_list)\n",
    "    average_f1 = f1_sum / len(src_text_list)\n",
    "    csv_frame = csv_frame.append({\"AVERAGE_RECALL\": average_recall, \"AVERAGE_PRECISION\": average_precision, \"AVERAGE_F1\": average_f1}, ignore_index=True)\n",
    "    csv_frame.to_csv(filename, index=False)\n",
    "\n",
    "# Training Data Tagalog to Ilokano \n",
    "dict_tl_il_result = pd.read_json('../src/json data/Tagalog to Ilokano/Hybrid Translator/dict_tl-il_op_ex.json')\n",
    "src_text_list = dict_tl_il_result['Source Text'].tolist()\n",
    "tgt_op_list = dict_tl_il_result['Target Output'].tolist()\n",
    "sys_op_list = dict_tl_il_result['System Output'].tolist()\n",
    "compute_rouge_score(src_text_list, tgt_op_list, sys_op_list, '../src/scores/Tagalog to Ilokano/train/train_rouge_tl-il.csv')\n",
    "\n",
    "# Training Data Ilokano to Tagalog\n",
    "dict_il_tl_result = pd.read_json('../src/json data/Ilokano to Tagalog/Hybrid Translator/dict_il-tl_op_ex.json')\n",
    "src_text_list = dict_il_tl_result['Source Text'].tolist()\n",
    "tgt_op_list = dict_il_tl_result['Target Output'].tolist()\n",
    "sys_op_list = dict_il_tl_result['System Output'].tolist()\n",
    "compute_rouge_score(src_text_list, tgt_op_list, sys_op_list, '../src/scores/Ilokano to Tagalog/train/train_rouge_il-tl.csv')\n",
    "\n",
    "# Testing Data Tagalog to Ilokano\n",
    "dict_tl_il_result = pd.read_json('../src/json data/Tagalog to Ilokano/Hybrid Translator/dict_tl-il_test.json')\n",
    "src_text_list = dict_tl_il_result['Source Text'].tolist()\n",
    "tgt_op_list = dict_tl_il_result['Target Output'].tolist()\n",
    "sys_op_list = dict_tl_il_result['System Output'].tolist()\n",
    "compute_rouge_score(src_text_list, tgt_op_list, sys_op_list, '../src/scores/Tagalog to Ilokano/test/test_rouge_tl-il.csv')\n",
    "\n",
    "# Testing Data Ilokano to Tagalog\n",
    "dict_il_tl_result = pd.read_json('../src/json data/Ilokano to Tagalog/Hybrid Translator/dict_il-tl_test.json')\n",
    "src_text_list = dict_il_tl_result['Source Text'].tolist()\n",
    "tgt_op_list = dict_il_tl_result['Target Output'].tolist()\n",
    "sys_op_list = dict_il_tl_result['System Output'].tolist()\n",
    "compute_rouge_score(src_text_list, tgt_op_list, sys_op_list, '../src/scores/Ilokano to Tagalog/test/test_rouge_il-tl.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1d54cc6ba22d92170a9f9c24d6077688435e22a85a4273e6fe4e4e6bdebfd02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
